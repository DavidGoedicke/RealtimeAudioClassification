{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "In this notebook we take the generated images in the ``eneratedData`` folder and use them to train a neural network.\n",
    "\n",
    "### What does it all do?\n",
    "We will walk througho the main steps so you can understand in basics steps in this notebook. \n",
    "\n",
    "---\n",
    "\n",
    "First we need to import a couple of different libraries. You can see many of them contain the name ```troch```, this is the main machine learning library we will use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nnAudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:25.120376Z",
     "start_time": "2020-08-02T21:29:25.114187Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import soundfile as sf\n",
    "import scipy.signal as sps\n",
    "from nnAudio import Spectrogram\n",
    "\n",
    "\n",
    "#### NOOOOO\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classes to train\n",
    "\n",
    "The less classes you have  the fewer data you need. So slecting just the right ammount of classes can be one way to reduce the ammount of processing and increase, potentially, the reliabilty.\n",
    "\n",
    "In the following section you can select which of the found classes should be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:25.860651Z",
     "start_time": "2020-08-02T21:29:25.783158Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select classes to use for training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f73dbbf3fba45e193e3f00f34b69148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='air_conditioner', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0584b751cb7475ea73696f10b804fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='car_horn', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc60a08a0a045278345b279bd98b3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='children_playing', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb4b2525ca34d59b8965291bef54344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='dog_bark', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb83ea14b5f48c68a736bb26f1cdad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='drilling', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c649b2b23b624fc584a58b08ca1b5602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='engine_idling', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c013313f9047758e42c99ab3d18a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='environment', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3e7e5bd83b4594a0f7a70e08933685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='gun_shot', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae2b52989d148049bb5b111bebc45ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='jackhammer', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7742e15f506846ad923546fc68cd5001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='siren', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49186eea5cb841b49def38b4f211c395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='street_music', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Type=\"TRAINING\"\n",
    "exec(open(\"../helperFunctions.py\",\"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:41.596014Z",
     "start_time": "2020-08-02T21:29:41.590541Z"
    }
   },
   "outputs": [],
   "source": [
    "UsedClasses=[]\n",
    "for k in widgetDict:\n",
    "    if widgetDict[k].value==True:\n",
    "        UsedClasses.append(k)\n",
    "if(len(UsedClasses)<2):\n",
    "    print(\"Something is wrong here. we need at least 2 classes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UsedClasses=['street_music' ,'siren' ,'jackhammer' ,'engine_idling' ,'drilling' ,'dog_bark' ,'children_playing' ,'air_conditioner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UsedClasses=['street_music' ,'siren' ,'children_playing' ,'dog_bark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data set\n",
    "If test set is not defined previously, this function pulls a test set from the training set using a 80/20%split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT='../AudioData/'\n",
    "\n",
    "class AudioData(torch.utils.data.Dataset):\n",
    "            \"\"\"Face Landmarks dataset.\"\"\"\n",
    "            def __init__(self, classNumber, ClassName,root_dir,device):\n",
    "                \"\"\"\n",
    "                Args:\n",
    "                    root_dir (string): Directory with all the images.\n",
    "                    transform (callable, optional): Optional transform to be applied\n",
    "                        on a sample.\n",
    "                \"\"\"\n",
    "                self.root_dir = root_dir\n",
    "                self.ClassName=ClassName\n",
    "                self.classNumber=classNumber\n",
    "                #self.fileList=[]\n",
    "                self.audioList=[]\n",
    "                for f in os.listdir(root_dir):\n",
    "                    if(f.endswith('.DS_Store')):\n",
    "                        continue\n",
    "                    if librosa.get_duration(filename=os.path.join(root_dir,f))>=1.06:\n",
    "                        y, sr = librosa.load(os.path.join(root_dir,f),duration=1.05, sr=22050,mono=True)\n",
    "                        #print(len(y))\n",
    "                        self.audioList.append(np.array(y))\n",
    "                        #self.fileList.append(f)\n",
    "                self.device = device\n",
    "                print(\"Done with class\", self.ClassName,len(self.audioList),len(self.audioList[0]));\n",
    "            \n",
    "            def __len__(self):\n",
    "                return len(self.audioList) # self.fileList\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                if torch.is_tensor(idx):\n",
    "                    idx = idx.tolist()\n",
    "                #audio_path = os.path.join(self.root_dir,self.fileList[idx])\n",
    "               \n",
    "                #sr, song = wavfile.read(audio_path) # Loading your audio\n",
    "               # data_, samplerate = sf.read(audio_path,always_2d=True)\n",
    "                #data=data_.T[0]\n",
    "                 # Your new sampling rate\n",
    "                #new_rate = 22050\n",
    "\n",
    "                # Resample data\n",
    "               # number_of_samples = round(len(data) * float(new_rate) / samplerate)\n",
    "                #data = sps.resample(data, number_of_samples)\n",
    "                #y, sr = librosa.load(audio_path,duration=0.41, sr=22050,mono=True)\n",
    "                \n",
    "                x = self.audioList[idx][0:22050]  # y[0:8820]\n",
    "                #print(x.shape,audio_path)\n",
    "                x = torch.tensor(x, device=self.device).float() \n",
    "                return x,self.classNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.index(\"air_conditioner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:44.497868Z",
     "start_time": "2020-08-02T21:29:44.446826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with class street_music 1000 23153\n",
      "Done with class siren 915 23153\n",
      "Done with class children_playing 999 23153\n",
      "Done with class dog_bark 853 23153\n"
     ]
    }
   ],
   "source": [
    "classes =  tuple(UsedClasses)\n",
    "\n",
    "\n",
    "AllData=[]\n",
    "\n",
    "for cl in classes:   \n",
    "    trainPath=os.path.join(ROOT,cl)\n",
    "    if os.path.isdir (trainPath):\n",
    "        AllData.append( AudioData(classes.index(cl), cl,trainPath,device))\n",
    "    else:\n",
    "        print('Coud not find path',trainPath);\n",
    "        \n",
    "\n",
    "AllDataSets = torch.utils.data.ConcatDataset(AllData);\n",
    "trainSize = int(len(AllDataSets)*0.8);\n",
    "testSize = len(AllDataSets) - trainSize;\n",
    "\n",
    "\n",
    "TrainDataSet, TestDataSet = torch.utils.data.random_split(AllDataSets, [trainSize, testSize],generator=torch.Generator().manual_seed(42))\n",
    "trainloader = torch.utils.data.DataLoader(TrainDataSet, batch_size=1024, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(TestDataSet, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[street_music ,siren ,jackhammer ,engine_idling ,drilling ,dog_bark ,children_playing ,air_conditioner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:36:02.653653Z",
     "start_time": "2020-08-02T20:36:02.539338Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,classCount):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.mel = nnAudio.Spectrogram.MelSpectrogram(n_fft=1536, n_mels=192, trainable_mel=True, trainable_STFT=True).cuda(device) # Using device='cuda:0'\n",
    "        torch.nn.init.xavier_uniform_(self.mel.mel_basis)\n",
    "        self.CNN_layer1 = torch.nn.Conv2d(1,4, kernel_size=(12,12)).cuda(device)\n",
    "        self.CNN_layer2 = torch.nn.Conv2d(4,16, kernel_size=(24,24)).cuda(device)\n",
    "        self.mpool = nn.MaxPool2d(4)\n",
    "        self.fc1 = torch.nn.Linear(16* 39* 2,128).cuda(device)\n",
    "        self.fc2 = torch.nn.Linear(128,classCount).cuda(device)\n",
    "    def visualize(sound):\n",
    "        return self.mel(sound)\n",
    "    def forward(self, x):\n",
    "        x = self.mel(x)\n",
    "        #print(x.shape)\n",
    "        x = self.CNN_layer1(x.unsqueeze(1))\n",
    "        x = self.CNN_layer2(x)\n",
    "        x = self.mpool(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.data.size()[0],16* 39* 2)\n",
    "        x = self.fc1(torch.relu(x))\n",
    "        x = self.fc2(torch.relu(x))\n",
    "        return torch.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:16.669357Z",
     "start_time": "2020-08-02T20:42:16.661468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.0449 seconds\n",
      "STFT filter created, time used = 0.0030 seconds\n",
      "Mel filter created, time used = 0.0030 seconds\n"
     ]
    }
   ],
   "source": [
    "model=Model(len(classes))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "train_epoch_losses=[]\n",
    "test_epoch_losses=[]\n",
    "epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:00.245670Z",
     "start_time": "2020-08-02T20:42:29.699734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 1\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "2 train loss: 1.438 and test loss: 1.428, and it took us: 1.89 seconds.\n",
      "Starting epoch: 2\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "3 train loss: 1.426 and test loss: 1.428, and it took us: 1.66 seconds.\n",
      "Starting epoch: 3\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "4 train loss: 1.413 and test loss: 1.421, and it took us: 1.53 seconds.\n",
      "Starting epoch: 4\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "5 train loss: 1.412 and test loss: 1.419, and it took us: 1.58 seconds.\n",
      "Starting epoch: 5\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "6 train loss: 1.405 and test loss: 1.415, and it took us: 1.58 seconds.\n",
      "Starting epoch: 6\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "7 train loss: 1.400 and test loss: 1.414, and it took us: 1.67 seconds.\n",
      "Starting epoch: 7\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "8 train loss: 1.395 and test loss: 1.412, and it took us: 1.57 seconds.\n",
      "Starting epoch: 8\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "9 train loss: 1.392 and test loss: 1.410, and it took us: 1.57 seconds.\n",
      "Starting epoch: 9\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "10 train loss: 1.388 and test loss: 1.408, and it took us: 1.61 seconds.\n",
      "Starting epoch: 10\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "11 train loss: 1.385 and test loss: 1.408, and it took us: 1.56 seconds.\n",
      "Starting epoch: 11\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "12 train loss: 1.381 and test loss: 1.407, and it took us: 1.60 seconds.\n",
      "Starting epoch: 12\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "13 train loss: 1.378 and test loss: 1.404, and it took us: 1.61 seconds.\n",
      "Starting epoch: 13\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "14 train loss: 1.375 and test loss: 1.403, and it took us: 1.56 seconds.\n",
      "Starting epoch: 14\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "15 train loss: 1.373 and test loss: 1.404, and it took us: 1.60 seconds.\n",
      "Starting epoch: 15\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "16 train loss: 1.370 and test loss: 1.403, and it took us: 1.65 seconds.\n",
      "Starting epoch: 16\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "17 train loss: 1.367 and test loss: 1.402, and it took us: 1.57 seconds.\n",
      "Starting epoch: 17\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "18 train loss: 1.364 and test loss: 1.404, and it took us: 1.62 seconds.\n",
      "Starting epoch: 18\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "19 train loss: 1.363 and test loss: 1.401, and it took us: 1.71 seconds.\n",
      "Starting epoch: 19\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "20 train loss: 1.359 and test loss: 1.396, and it took us: 1.57 seconds.\n",
      "Starting epoch: 20\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "21 train loss: 1.358 and test loss: 1.395, and it took us: 1.62 seconds.\n",
      "Starting epoch: 21\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "22 train loss: 1.355 and test loss: 1.397, and it took us: 1.65 seconds.\n",
      "Starting epoch: 22\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "23 train loss: 1.354 and test loss: 1.395, and it took us: 1.57 seconds.\n",
      "Starting epoch: 23\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "24 train loss: 1.352 and test loss: 1.391, and it took us: 1.59 seconds.\n",
      "Starting epoch: 24\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "25 train loss: 1.350 and test loss: 1.388, and it took us: 1.65 seconds.\n",
      "Starting epoch: 25\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "26 train loss: 1.348 and test loss: 1.387, and it took us: 1.57 seconds.\n",
      "Starting epoch: 26\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "27 train loss: 1.346 and test loss: 1.386, and it took us: 1.61 seconds.\n",
      "Starting epoch: 27\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "28 train loss: 1.345 and test loss: 1.385, and it took us: 1.71 seconds.\n",
      "Starting epoch: 28\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "29 train loss: 1.343 and test loss: 1.385, and it took us: 1.58 seconds.\n",
      "Starting epoch: 29\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "30 train loss: 1.341 and test loss: 1.383, and it took us: 1.63 seconds.\n",
      "Starting epoch: 30\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "31 train loss: 1.340 and test loss: 1.382, and it took us: 1.69 seconds.\n",
      "Starting epoch: 31\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "32 train loss: 1.339 and test loss: 1.382, and it took us: 1.57 seconds.\n",
      "Starting epoch: 32\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "33 train loss: 1.337 and test loss: 1.381, and it took us: 1.62 seconds.\n",
      "Starting epoch: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "34 train loss: 1.336 and test loss: 1.380, and it took us: 1.61 seconds.\n",
      "Starting epoch: 34\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "35 train loss: 1.335 and test loss: 1.380, and it took us: 1.64 seconds.\n",
      "Starting epoch: 35\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "36 train loss: 1.333 and test loss: 1.379, and it took us: 1.62 seconds.\n",
      "Starting epoch: 36\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "37 train loss: 1.332 and test loss: 1.379, and it took us: 1.67 seconds.\n",
      "Starting epoch: 37\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "38 train loss: 1.331 and test loss: 1.379, and it took us: 1.65 seconds.\n",
      "Starting epoch: 38\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "39 train loss: 1.330 and test loss: 1.380, and it took us: 1.61 seconds.\n",
      "Starting epoch: 39\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "40 train loss: 1.329 and test loss: 1.377, and it took us: 1.61 seconds.\n",
      "Starting epoch: 40\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "41 train loss: 1.328 and test loss: 1.376, and it took us: 1.63 seconds.\n",
      "Starting epoch: 41\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "42 train loss: 1.327 and test loss: 1.375, and it took us: 1.62 seconds.\n",
      "Starting epoch: 42\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "43 train loss: 1.325 and test loss: 1.377, and it took us: 1.63 seconds.\n",
      "Starting epoch: 43\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "44 train loss: 1.324 and test loss: 1.376, and it took us: 1.64 seconds.\n",
      "Starting epoch: 44\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "45 train loss: 1.322 and test loss: 1.375, and it took us: 1.62 seconds.\n",
      "Starting epoch: 45\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "46 train loss: 1.320 and test loss: 1.371, and it took us: 1.65 seconds.\n",
      "Starting epoch: 46\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "47 train loss: 1.314 and test loss: 1.365, and it took us: 1.67 seconds.\n",
      "Starting epoch: 47\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "48 train loss: 1.308 and test loss: 1.355, and it took us: 1.65 seconds.\n",
      "Starting epoch: 48\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "49 train loss: 1.306 and test loss: 1.347, and it took us: 1.65 seconds.\n",
      "Starting epoch: 49\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "50 train loss: 1.303 and test loss: 1.347, and it took us: 1.72 seconds.\n",
      "Starting epoch: 50\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "51 train loss: 1.299 and test loss: 1.350, and it took us: 1.64 seconds.\n",
      "Starting epoch: 51\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "52 train loss: 1.293 and test loss: 1.342, and it took us: 1.67 seconds.\n",
      "Starting epoch: 52\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "53 train loss: 1.293 and test loss: 1.341, and it took us: 1.68 seconds.\n",
      "Starting epoch: 53\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "54 train loss: 1.286 and test loss: 1.341, and it took us: 1.66 seconds.\n",
      "Starting epoch: 54\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "55 train loss: 1.282 and test loss: 1.338, and it took us: 1.69 seconds.\n",
      "Starting epoch: 55\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "56 train loss: 1.278 and test loss: 1.330, and it took us: 1.84 seconds.\n",
      "Starting epoch: 56\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "57 train loss: 1.273 and test loss: 1.325, and it took us: 1.68 seconds.\n",
      "Starting epoch: 57\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "58 train loss: 1.268 and test loss: 1.324, and it took us: 1.65 seconds.\n",
      "Starting epoch: 58\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "59 train loss: 1.263 and test loss: 1.320, and it took us: 1.79 seconds.\n",
      "Starting epoch: 59\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "60 train loss: 1.259 and test loss: 1.317, and it took us: 1.64 seconds.\n",
      "Starting epoch: 60\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "61 train loss: 1.255 and test loss: 1.314, and it took us: 1.74 seconds.\n",
      "Starting epoch: 61\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "62 train loss: 1.252 and test loss: 1.310, and it took us: 1.74 seconds.\n",
      "Starting epoch: 62\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "63 train loss: 1.248 and test loss: 1.309, and it took us: 1.69 seconds.\n",
      "Starting epoch: 63\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "64 train loss: 1.244 and test loss: 1.306, and it took us: 1.73 seconds.\n",
      "Starting epoch: 64\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "65 train loss: 1.241 and test loss: 1.304, and it took us: 1.73 seconds.\n",
      "Starting epoch: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "66 train loss: 1.238 and test loss: 1.303, and it took us: 1.69 seconds.\n",
      "Starting epoch: 66\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "67 train loss: 1.235 and test loss: 1.301, and it took us: 1.74 seconds.\n",
      "Starting epoch: 67\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "68 train loss: 1.233 and test loss: 1.298, and it took us: 1.71 seconds.\n",
      "Starting epoch: 68\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "69 train loss: 1.231 and test loss: 1.295, and it took us: 1.71 seconds.\n",
      "Starting epoch: 69\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "70 train loss: 1.228 and test loss: 1.296, and it took us: 1.77 seconds.\n",
      "Starting epoch: 70\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "71 train loss: 1.226 and test loss: 1.294, and it took us: 1.68 seconds.\n",
      "Starting epoch: 71\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "72 train loss: 1.223 and test loss: 1.294, and it took us: 1.81 seconds.\n",
      "Starting epoch: 72\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "73 train loss: 1.222 and test loss: 1.289, and it took us: 1.72 seconds.\n",
      "Starting epoch: 73\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "74 train loss: 1.220 and test loss: 1.292, and it took us: 1.79 seconds.\n",
      "Starting epoch: 74\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "75 train loss: 1.219 and test loss: 1.289, and it took us: 1.66 seconds.\n",
      "Starting epoch: 75\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "76 train loss: 1.216 and test loss: 1.288, and it took us: 1.77 seconds.\n",
      "Starting epoch: 76\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "77 train loss: 1.214 and test loss: 1.284, and it took us: 1.74 seconds.\n",
      "Starting epoch: 77\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "78 train loss: 1.213 and test loss: 1.285, and it took us: 1.72 seconds.\n",
      "Starting epoch: 78\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "79 train loss: 1.212 and test loss: 1.283, and it took us: 1.77 seconds.\n",
      "Starting epoch: 79\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "80 train loss: 1.210 and test loss: 1.284, and it took us: 1.66 seconds.\n",
      "Starting epoch: 80\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "81 train loss: 1.209 and test loss: 1.283, and it took us: 1.73 seconds.\n",
      "Starting epoch: 81\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "82 train loss: 1.207 and test loss: 1.281, and it took us: 1.78 seconds.\n",
      "Starting epoch: 82\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "83 train loss: 1.206 and test loss: 1.280, and it took us: 1.70 seconds.\n",
      "Starting epoch: 83\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "84 train loss: 1.205 and test loss: 1.280, and it took us: 1.73 seconds.\n",
      "Starting epoch: 84\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "85 train loss: 1.204 and test loss: 1.281, and it took us: 1.77 seconds.\n",
      "Starting epoch: 85\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "86 train loss: 1.203 and test loss: 1.279, and it took us: 1.79 seconds.\n",
      "Starting epoch: 86\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "87 train loss: 1.201 and test loss: 1.277, and it took us: 1.68 seconds.\n",
      "Starting epoch: 87\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "88 train loss: 1.200 and test loss: 1.276, and it took us: 1.79 seconds.\n",
      "Starting epoch: 88\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "89 train loss: 1.199 and test loss: 1.277, and it took us: 1.71 seconds.\n",
      "Starting epoch: 89\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "90 train loss: 1.198 and test loss: 1.277, and it took us: 1.90 seconds.\n",
      "Starting epoch: 90\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "91 train loss: 1.197 and test loss: 1.274, and it took us: 1.64 seconds.\n",
      "Starting epoch: 91\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "92 train loss: 1.196 and test loss: 1.274, and it took us: 1.73 seconds.\n",
      "Starting epoch: 92\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "93 train loss: 1.195 and test loss: 1.274, and it took us: 1.76 seconds.\n",
      "Starting epoch: 93\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "94 train loss: 1.194 and test loss: 1.274, and it took us: 1.65 seconds.\n",
      "Starting epoch: 94\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "95 train loss: 1.192 and test loss: 1.273, and it took us: 1.75 seconds.\n",
      "Starting epoch: 95\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "96 train loss: 1.192 and test loss: 1.272, and it took us: 1.84 seconds.\n",
      "Starting epoch: 96\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "97 train loss: 1.191 and test loss: 1.271, and it took us: 1.72 seconds.\n",
      "Starting epoch: 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "98 train loss: 1.190 and test loss: 1.271, and it took us: 1.74 seconds.\n",
      "Starting epoch: 98\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "99 train loss: 1.189 and test loss: 1.271, and it took us: 1.79 seconds.\n",
      "Starting epoch: 99\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "100 train loss: 1.188 and test loss: 1.269, and it took us: 1.70 seconds.\n",
      "Starting epoch: 100\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([1024, 16, 39, 2])\n",
      "torch.Size([965, 16, 39, 2])\n",
      "About to test the performance on the test set.\n",
      "torch.Size([754, 16, 39, 2])\n",
      "101 train loss: 1.187 and test loss: 1.268, and it took us: 1.77 seconds.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#### Training the network on the training dataset\n",
    "for i in range(100):  # loop over the dataset multiple (5) times \n",
    "    epoch+=1\n",
    "    print(\"Starting epoch:\",epoch)\n",
    "    epochLoss=0.0\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        #print(\"Loaded\")\n",
    "        #print(inputs.shape)\n",
    "        inputs = inputs.cuda(device)\n",
    "        labels = labels.cuda(device)\n",
    "        #print(\"move to cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        if((i+i)%50==0):\n",
    "            if(i>0):\n",
    "                print('Processed images:',i*trainloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        #print(\"move through model\")\n",
    "        #print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(\"loss done\")\n",
    "        loss.backward()\n",
    "        #print(\"backprop\")\n",
    "        optimizer.step()\n",
    "        #print(\"optimize done\")\n",
    "        epochLoss+=loss.item()\n",
    "        \n",
    "    \n",
    "    model.eval()\n",
    "    testLoss=0\n",
    "    print(\"About to test the performance on the test set.\")\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(testloader, 0):\n",
    "            # get the inputs\n",
    "            inputs = inputs.cuda(device)\n",
    "            labels = labels.cuda(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            testLoss+=loss.item()\n",
    "            if(i%50==0):\n",
    "                if(i>0):\n",
    "                    print('Tested images:',i*testloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "\n",
    "\n",
    "    train_epoch_losses.append(epochLoss/len(trainloader))\n",
    "    test_epoch_losses.append(testLoss/len(testloader))\n",
    "    EpochLength = time.time()-t0\n",
    "    print('{} train loss: {:.3f} and test loss: {:.3f}, and it took us: {:.2f} seconds.'.format (epoch + 1, epochLoss / len(trainloader),testLoss/len(testloader),EpochLength))  # DAVID CHanged it to 1000 from 2000 not sure if thats totally done\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post training analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training has finished, save information about the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:08.058441Z",
     "start_time": "2020-08-02T20:44:07.767189Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving the learnd model in file that can be loaded in for inference\n",
    "torch.save({\n",
    "    'model':model.state_dict(),\n",
    "    'classes':classes,\n",
    "    'resolution':224,\n",
    "    'modelType':\"resnet18\" # <= If you try out different models make sure to change this too\n",
    "},\"../models/CatDogResNet.pth\") # <=Edit file name here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display how the traing and test loss progressed over successive epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:09.700714Z",
     "start_time": "2020-08-02T20:44:09.070817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying how the loss progresses over time.\n",
    "plt.plot(train_epoch_losses, label='Training Loss',c='r')\n",
    "plt.plot(test_epoch_losses, label='Test Loss',c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show spectagrams, Predicted and Actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:12.759024Z",
     "start_time": "2020-08-02T20:44:12.697637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print predicted and acual labels for Spectragrams\n",
    "model.eval()\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "for i in range(trainloader.batch_size):\n",
    "    imshow(images[i].cpu())\n",
    "    print('GroundTruth: ',classes[labels[i]])\n",
    "    print('Predicted: ',  classes[predicted[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracy of test predictions for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:15.905168Z",
     "start_time": "2020-08-02T20:44:14.974999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([754, 16, 161, 13])\n",
      "[[128  12  53   9]\n",
      " [ 11 103  56   3]\n",
      " [ 42  21 132  17]\n",
      " [ 19  20  54  74]]\n",
      "Accuracy of street_music : 63 %\n",
      "Accuracy of siren : 59 %\n",
      "Accuracy of children_playing : 62 %\n",
      "Accuracy of dog_bark : 44 %\n",
      "Average percentage:\t57%\n"
     ]
    }
   ],
   "source": [
    "# Network analytics\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "model.eval()\n",
    "allLabels=[]\n",
    "allPrediction=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda(device)\n",
    "        labels = labels.cuda(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        if (c.dim()==0):\n",
    "            continue\n",
    "        for i in range(testloader.batch_size):\n",
    "            if(len(labels)<=i):\n",
    "                continue;\n",
    "            label = labels[i]\n",
    "            allLabels.append(labels[i].to('cpu').numpy())\n",
    "            allPrediction.append(predicted[i].to('cpu').numpy())\n",
    "            #print (c.shape)\n",
    "            if(testloader.batch_size>1):\n",
    "                class_correct[label] += c[i].item()\n",
    "            else:\n",
    "                class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(confusion_matrix(allLabels, allPrediction))\n",
    "averagePercentage = []\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    averagePercentage.append( 100 * class_correct[i] / class_total[i])\n",
    "print(\"Average percentage:\\t%2d%%\"%(np.mean(averagePercentage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,classCount):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.mel = nnAudio.Spectrogram.MelSpectrogram(n_fft=2048, n_mels=64, trainable_mel=True, trainable_STFT=True).cuda(device) # Using device='cuda:0'\n",
    "\n",
    "        self.CNN_layer1 = torch.nn.Conv2d(1,1, kernel_size=(16,16)).cuda(device)\n",
    "        self.CNN_layer2 = torch.nn.Conv2d(1,1, kernel_size=(4,4)).cuda(device)\n",
    "        \n",
    "        self.regressor = torch.nn.Linear(46*26,classCount).cuda(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.mel(x)\n",
    "        x = self.CNN_layer1(x.unsqueeze(1))\n",
    "        x = self.CNN_layer2(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.data.size()[0], 46*26)\n",
    "        x=torch.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.regressor(torch.relu(x))\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[[118  11  39  26]\n",
    " [ 12  81  55  20]\n",
    " [ 39  15 128  28]\n",
    " [ 25   5  22 159]]\n",
    "Accuracy of street_music : 60 %\n",
    "Accuracy of siren : 48 %\n",
    "Accuracy of children_playing : 60 %\n",
    "Accuracy of air_conditioner : 75 %\n",
    "Average percentage:\t61%\n",
    "'''\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,classCount):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.mel = nnAudio.Spectrogram.MelSpectrogram(n_fft=1024, n_mels=128, trainable_mel=True, trainable_STFT=True).cuda(device) # Using device='cuda:0'\n",
    "        torch.nn.init.xavier_uniform_(self.mel.mel_basis)\n",
    "        self.CNN_layer1 = torch.nn.Conv2d(1,8, kernel_size=(16,16)).cuda(device)\n",
    "        self.CNN_layer2 = torch.nn.Conv2d(8,16, kernel_size=(16,16)).cuda(device)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(16* 98* 14,128).cuda(device)\n",
    "        self.fc2 = torch.nn.Linear(128,classCount).cuda(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mel(x)\n",
    "        #print(x.shape)\n",
    "        x = self.CNN_layer1(x.unsqueeze(1))\n",
    "        x = self.CNN_layer2(x)\n",
    "\n",
    "       # print(x.shape)\n",
    "        x = x.view(x.data.size()[0],16* 98* 14)\n",
    "        x = self.fc1(torch.relu(x))\n",
    "        x = self.fc2(torch.relu(x))\n",
    "        return torch.softmax(x,dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
